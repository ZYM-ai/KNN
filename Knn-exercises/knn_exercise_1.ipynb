{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. データセット wine に対して， 最初の行の例題を評価用， 残りの行の例題を訓練用として， 最近傍識別を行え． ただし，k-最近傍識別器 の近傍数は k=1 とせよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn import neighbors\n",
    "\n",
    "data=pd.read_csv(\"yXT_wine.csv\", header=None)\n",
    "y=data.pop(0).values\n",
    "\n",
    "y_test=y[0]\n",
    "y_train=y[1:]\n",
    "\n",
    "data_test=data.loc[0]\n",
    "data_train=data.loc[1::]\n",
    "\n",
    "knn=neighbors.KNeighborsClassifier(n_neighbors=1)\n",
    "knn.fit(data_train, y_train)\n",
    "pre=knn.predict([data_test])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. 各データセットに対して， 最初の行の例題を評価用， 残りの行の例題を訓練用として， 最近傍識別を行え． ただし，k-最近傍識別器 の近傍数は k=1 とせよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import neighbors\n",
    "\n",
    "dataset=['yXT_car.csv','yXT_seeds.csv','yXT_yeast.csv','yXT_winequality-white.csv']\n",
    "pre=[]\n",
    "for i in range(len(dataset)):\n",
    "    data=pd.read_csv(dataset[i],header=None)\n",
    "    y=data.pop(0).values\n",
    "    y_test=y[0]\n",
    "    y_train=y[1:]\n",
    "\n",
    "    data_test=data.loc[0]\n",
    "    data_train=data.loc[1::]\n",
    "\n",
    "    knn=neighbors.KNeighborsClassifier(n_neighbors=1)\n",
    "    knn.fit(data_train, y_train)\n",
    "    pre=knn.predict([data_test])\n",
    "    #print(pre==y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. データセット wine に対して， 各クラスのデータを訓練用と評価用を 7:3 にランダムに分けよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data=pd.read_csv(\"yXT_wine.csv\", header=None)\n",
    "xtrain, xtest, ytrain, ytest=train_test_split(data, data[0], test_size=0.3, stratify=data[0],random_state=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. データセット wine に対して， k-最近傍識別器 の k=1 とし，評価用データの識別率を出せ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7592592592592593"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn=neighbors.KNeighborsClassifier(n_neighbors=1)\n",
    "knn.fit(xtrain, ytrain)\n",
    "knn.score(xtest,ytest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. step-3を１０回繰り返して，識別率の平均値と標準偏差を算出せよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7537037037037038\n",
      "0.026254531256958938\n"
     ]
    }
   ],
   "source": [
    "data=pd.read_csv(\"yXT_wine.csv\", header=None)\n",
    "knn=neighbors.KNeighborsClassifier(n_neighbors=1)\n",
    "score=[]\n",
    "for i in range(10):\n",
    "    xtrain,xtest,ytrain,ytest=train_test_split(data, data[0], test_size=0.3, stratify=data[0])\n",
    "    knn.fit(xtrain,ytrain)\n",
    "    score.append(knn.score(xtest, ytest))\n",
    "print(np.mean(score))\n",
    "print(np.std(score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. 各データセットに対して，各クラスのデータを訓練用と評価用を 7:3 にランダムに分け，k-最近傍識別器 の k=1 とし， 評価用データの識別率を出せ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.636734693877551]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset=['yXT_car.csv','yXT_seeds.csv','yXT_yeast.csv','yXT_winequality-white.csv']\n",
    "sco_car=[]\n",
    "sco_seeds=[]\n",
    "sco_yeast=[]\n",
    "sco_winequality=[]\n",
    "score=[sco_car,sco_seeds,sco_yeast,sco_winequality]\n",
    "for i in range(len(dataset)):\n",
    "    data=pd.read_csv(dataset[i],header=None)\n",
    "    xtrain,xtest,ytrain,ytest=train_test_split(data, data[0], test_size=0.3, stratify=data[0])\n",
    "    \n",
    "    knn=neighbors.KNeighborsClassifier(n_neighbors=1)\n",
    "    knn.fit(xtrain, ytrain)\n",
    "    score[i].append(knn.score(xtest,ytest))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. 各データセットに対して，6. を１０回繰り返して，識別率の平均値と標準偏差を算出せよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean:[0.9996146435452793, 0.9974263693916873, 0.9982842462611249, 0.9039852935393811] \n",
      " std:[0.0007707129094412402, 0.00561609912846056, 0.0047433059912571135, 0.16345174725595227]\n"
     ]
    }
   ],
   "source": [
    "knn=neighbors.KNeighborsClassifier(n_neighbors=1)\n",
    "dataset=['yXT_car.csv','yXT_seeds.csv','yXT_yeast.csv','yXT_winequality-white.csv']\n",
    "score=[]\n",
    "mean=[]\n",
    "std=[]\n",
    "for i in range(len(dataset)):\n",
    "    data=pd.read_csv(dataset[i],header=None)\n",
    "    for j in range(10):\n",
    "        xtrain,xtest,ytrain,ytest=train_test_split(data, data[0], test_size=0.3, stratify=data[0])\n",
    "        knn.fit(xtrain, ytrain)\n",
    "        score.append(knn.score(xtest,ytest))\n",
    "    mean.append(np.mean(score))\n",
    "    std.append(np.std(score))\n",
    "print(\"mean:%s \\n std:%s\" %(mean, std))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. k-最近傍識別器 の k=1,2,3,4,5 を試せ． ただし，重みつきの voting をせよ． 重みは exp( - (ユークリッド距離)^2/(2σ^2)) で求めよ． ただし，σは訓練用データの距離値の中間値とする． これは，距離行列 D をまず計算し，median(D(:)) から求める．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-143-5d972c27f4f4>, line 80)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-143-5d972c27f4f4>\"\u001b[1;36m, line \u001b[1;32m80\u001b[0m\n\u001b[1;33m    print(\"k=%s:\",%(k), predict)\u001b[0m\n\u001b[1;37m                  ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import numpy.linalg as la\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import neighbors\n",
    "from numpy import array as matrix, arange\n",
    "import math\n",
    "\n",
    "data=pd.read_csv(\"yXT_wine.csv\", header=None)\n",
    "xtrain,xtest,ytrain,ytest=train_test_split(data, data[0], test_size=0.3, stratify=data[0],random_state=1)\n",
    "\n",
    "def compute_distance_1(X):\n",
    "  # determin dimensions of data matrix\n",
    "    m,n = X.shape\n",
    "  # initialize squared EDM D\n",
    "    D = np.zeros([n, n])\n",
    "  # iterate over upper triangle of D\n",
    "    for i in range(n):\n",
    "        for j in range(i+1, n):\n",
    "            d = X[:,i] - X[:,j]\n",
    "            D[i,j] = np.dot(d, d)**(1/2)\n",
    "            D[j,i] = D[i,j]\n",
    "    return D\n",
    "D1=compute_distance_1(matrix(xtrain.iloc[:,1:].transpose()))\n",
    "\n",
    "def compute_distance_2(X):\n",
    "  # determin dimensions of data matrix\n",
    "    m,n = X.shape\n",
    "  # initialize squared EDM D\n",
    "    D = np.zeros([n, n])\n",
    "  # iterate over upper triangle of D\n",
    "    for i in range(n):\n",
    "        for j in range(i+1, n):\n",
    "            D[i,j] = la.norm(X[:, i] - X[:, j])\n",
    "            D[j,i] = D[i,j]    #*1\n",
    "    return D\n",
    "D2=compute_distance_2(matrix(xtrain.iloc[:,1:].transpose()))\n",
    "sigma=np.median(D2)\n",
    "\n",
    "def gaussian_weight(dist, sigma = sigma):\n",
    "    \"\"\" Input a distance and return it`s weight\"\"\"\n",
    "    weight = np.exp(-dist**2/(2*sigma**2))\n",
    "    return weight\n",
    " \n",
    "### weighted_KNN\n",
    "def weighted_classify(input, dataSet, label, k):\n",
    "    classification=[]\n",
    "    for i in range(input.shape[0]):\n",
    "        \n",
    "        dataSize = dataSet.shape[0]\n",
    "        diff = np.tile(input.iloc[i,1::], (dataSize, 1)) - dataSet.iloc[:,1:]\n",
    "        sqdiff=diff**2\n",
    "        squareDist = np.array([sum(sqdiff.iloc[x,:]) for x in range(124)])\n",
    "        dist = squareDist**0.5\n",
    "        #print(input, dist[0], dist[])\n",
    "        sortedDistIndex = np.argsort(dist)\n",
    " \n",
    "        classCount = {}\n",
    "        for i in range(k):\n",
    "            index = sortedDistIndex[i]\n",
    "            label=list(label)\n",
    "            voteLabel = label[index]\n",
    "            weight = gaussian_weight(dist[index]) \n",
    "        #print(index, dist[index],weight)\n",
    "        ## 这里不再是加一，而是权重*1\n",
    "            classCount[voteLabel] = classCount.get(voteLabel, 0) + weight*1\n",
    "        \n",
    "        #print(classCount)\n",
    "        maxCount = 0\n",
    "        \n",
    "        for key, value in classCount.items():\n",
    "            if value > maxCount:\n",
    "                maxCount = value\n",
    "                classes = key\n",
    "        classification.append(classes)\n",
    "    return classification\n",
    "#predict=[]\n",
    "for k in range(1,6):\n",
    "    predict=weighted_classify(xtest, xtrain,ytrain,k)\n",
    "    print(\"k=%s:\",%(k), predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1      13.52\n",
       "2       3.17\n",
       "3       2.72\n",
       "4      23.50\n",
       "5      97.00\n",
       "6       1.55\n",
       "7       0.52\n",
       "8       0.50\n",
       "9       0.55\n",
       "10      4.35\n",
       "11      0.89\n",
       "12      2.06\n",
       "13    520.00\n",
       "Name: 142, dtype: float64"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtest.iloc[0,1::]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def gaussian(dist, sigma = 285.0):\n",
    "    \"\"\" Input a distance and return it`s weight\"\"\"\n",
    "    weight = np.exp(-dist**2/(2*sigma**2))\n",
    "    return weight\n",
    " \n",
    "### 加权KNN\n",
    "def weighted_classify(input, dataSet, label, k):\n",
    "    for i in range(input.shape[0]):\n",
    "        \n",
    "        dataSize = dataSet.shape[0]\n",
    "        diff = np.tile(input.iloc[i,1::], (dataSize, 1)) - dataSet.iloc[:,1:]\n",
    "        sqdiff=diff**2\n",
    "        squareDist = np.array([sum(sqdiff.iloc[x,:]) for x in range(124)])\n",
    "        dist = squareDist**0.5\n",
    "    #print(input, dist[0], dist[1164])\n",
    "        sortedDistIndex = np.argsort(dist)\n",
    " \n",
    "        classCount = {}\n",
    "        for i in range(k):\n",
    "            index = sortedDistIndex[i]\n",
    "            label=list(label)\n",
    "            voteLabel = label[index]\n",
    "            weight = gaussian(dist[index]) \n",
    "        #print(index, dist[index],weight)\n",
    "        ## 这里不再是加一，而是权重*1\n",
    "            classCount[voteLabel] = classCount.get(voteLabel, 0) + weight*1\n",
    "        \n",
    "        maxCount = 0\n",
    "    #print(classCount)\n",
    "   \n",
    "        for key, value in classCount.items():\n",
    "            if value > maxCount:\n",
    "                maxCount = value\n",
    "                classes = key\n",
    "        \n",
    "    return classes\n",
    "pre=weighted_classify(xtest, xtrain,ytrain,2)\n",
    "pre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "0.8626847069660394\n",
      "2\n",
      "0.7136690068267258\n"
     ]
    }
   ],
   "source": [
    "diff = np.tile(xtest.iloc[1,1::], (124, 1)) - xtrain.iloc[:,1:]\n",
    "diff=diff**2\n",
    "dist=np.array([sum(diff.iloc[x,:]) for x in range(124)])\n",
    "#np.array([sum(diff.iloc[1,::]))\n",
    "np.argsort(dist)[5]\n",
    "list(ytrain)[25]\n",
    "classCount = {3: 0.8626847069660394, 2: 0.7136690068267258}\n",
    "classCount.items()\n",
    "for key, value in classCount.items():\n",
    "    print(key)\n",
    "    print(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "515.067039034726"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "124"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit ('learn': conda)",
   "language": "python",
   "name": "python37664bitlearncondad4d4384a8da9442494deee9f96834118"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
